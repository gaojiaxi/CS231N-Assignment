{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.335194\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Since we have 10 classes.By randomly guessing we can expect a accuracy of 10%.So the loss should be -log(10%).*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -0.329629 analytic: -0.329629, relative error: 2.930453e-09\n",
      "numerical: -1.088759 analytic: -1.088759, relative error: 2.163796e-08\n",
      "numerical: -0.173619 analytic: -0.173619, relative error: 1.069199e-08\n",
      "numerical: -0.536759 analytic: -0.536759, relative error: 2.664452e-08\n",
      "numerical: 1.019125 analytic: 1.019125, relative error: 1.600626e-08\n",
      "numerical: 2.266784 analytic: 2.266784, relative error: 1.727992e-09\n",
      "numerical: -1.595846 analytic: -1.595846, relative error: 1.229368e-08\n",
      "numerical: 1.325198 analytic: 1.325198, relative error: 1.820931e-08\n",
      "numerical: 1.218314 analytic: 1.218314, relative error: 1.479011e-08\n",
      "numerical: 0.869913 analytic: 0.869913, relative error: 3.042145e-08\n",
      "numerical: 1.241501 analytic: 1.241501, relative error: 9.360033e-09\n",
      "numerical: 1.742699 analytic: 1.742699, relative error: 1.179461e-08\n",
      "numerical: 2.548132 analytic: 2.548132, relative error: 2.141626e-09\n",
      "numerical: 0.846289 analytic: 0.846289, relative error: 4.364208e-09\n",
      "numerical: -2.552033 analytic: -2.552033, relative error: 1.222146e-08\n",
      "numerical: -2.599868 analytic: -2.599868, relative error: 8.879298e-09\n",
      "numerical: 0.697790 analytic: 0.697790, relative error: 1.657953e-08\n",
      "numerical: 1.373333 analytic: 1.373333, relative error: 3.005631e-09\n",
      "numerical: -0.238277 analytic: -0.238277, relative error: 1.210050e-07\n",
      "numerical: 0.842539 analytic: 0.842539, relative error: 1.668945e-09\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.335194e+00 computed in 0.078000s\n",
      "vectorized loss: 2.335194e+00 computed in 0.000000s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.324918 val accuracy: 0.339000\n",
      "lr 1.000000e-07 reg 2.631579e+04 train accuracy: 0.323000 val accuracy: 0.334000\n",
      "lr 1.000000e-07 reg 2.763158e+04 train accuracy: 0.324531 val accuracy: 0.334000\n",
      "lr 1.000000e-07 reg 2.894737e+04 train accuracy: 0.324857 val accuracy: 0.342000\n",
      "lr 1.000000e-07 reg 3.026316e+04 train accuracy: 0.322245 val accuracy: 0.342000\n",
      "lr 1.000000e-07 reg 3.157895e+04 train accuracy: 0.327020 val accuracy: 0.335000\n",
      "lr 1.000000e-07 reg 3.289474e+04 train accuracy: 0.316551 val accuracy: 0.333000\n",
      "lr 1.000000e-07 reg 3.421053e+04 train accuracy: 0.323061 val accuracy: 0.337000\n",
      "lr 1.000000e-07 reg 3.552632e+04 train accuracy: 0.320122 val accuracy: 0.326000\n",
      "lr 1.000000e-07 reg 3.684211e+04 train accuracy: 0.315265 val accuracy: 0.330000\n",
      "lr 1.000000e-07 reg 3.815789e+04 train accuracy: 0.311816 val accuracy: 0.322000\n",
      "lr 1.000000e-07 reg 3.947368e+04 train accuracy: 0.318367 val accuracy: 0.334000\n",
      "lr 1.000000e-07 reg 4.078947e+04 train accuracy: 0.310367 val accuracy: 0.324000\n",
      "lr 1.000000e-07 reg 4.210526e+04 train accuracy: 0.317122 val accuracy: 0.334000\n",
      "lr 1.000000e-07 reg 4.342105e+04 train accuracy: 0.319510 val accuracy: 0.335000\n",
      "lr 1.000000e-07 reg 4.473684e+04 train accuracy: 0.315122 val accuracy: 0.334000\n",
      "lr 1.000000e-07 reg 4.605263e+04 train accuracy: 0.305959 val accuracy: 0.322000\n",
      "lr 1.000000e-07 reg 4.736842e+04 train accuracy: 0.310918 val accuracy: 0.323000\n",
      "lr 1.000000e-07 reg 4.868421e+04 train accuracy: 0.309143 val accuracy: 0.335000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.305551 val accuracy: 0.328000\n",
      "lr 1.210526e-07 reg 2.500000e+04 train accuracy: 0.329082 val accuracy: 0.341000\n",
      "lr 1.210526e-07 reg 2.631579e+04 train accuracy: 0.327755 val accuracy: 0.339000\n",
      "lr 1.210526e-07 reg 2.763158e+04 train accuracy: 0.322918 val accuracy: 0.340000\n",
      "lr 1.210526e-07 reg 2.894737e+04 train accuracy: 0.324408 val accuracy: 0.339000\n",
      "lr 1.210526e-07 reg 3.026316e+04 train accuracy: 0.322510 val accuracy: 0.330000\n",
      "lr 1.210526e-07 reg 3.157895e+04 train accuracy: 0.327143 val accuracy: 0.332000\n",
      "lr 1.210526e-07 reg 3.289474e+04 train accuracy: 0.312265 val accuracy: 0.324000\n",
      "lr 1.210526e-07 reg 3.421053e+04 train accuracy: 0.315796 val accuracy: 0.339000\n",
      "lr 1.210526e-07 reg 3.552632e+04 train accuracy: 0.315367 val accuracy: 0.337000\n",
      "lr 1.210526e-07 reg 3.684211e+04 train accuracy: 0.311653 val accuracy: 0.327000\n",
      "lr 1.210526e-07 reg 3.815789e+04 train accuracy: 0.314918 val accuracy: 0.332000\n",
      "lr 1.210526e-07 reg 3.947368e+04 train accuracy: 0.308796 val accuracy: 0.327000\n",
      "lr 1.210526e-07 reg 4.078947e+04 train accuracy: 0.317122 val accuracy: 0.334000\n",
      "lr 1.210526e-07 reg 4.210526e+04 train accuracy: 0.313796 val accuracy: 0.327000\n",
      "lr 1.210526e-07 reg 4.342105e+04 train accuracy: 0.312245 val accuracy: 0.330000\n",
      "lr 1.210526e-07 reg 4.473684e+04 train accuracy: 0.317184 val accuracy: 0.334000\n",
      "lr 1.210526e-07 reg 4.605263e+04 train accuracy: 0.309571 val accuracy: 0.330000\n",
      "lr 1.210526e-07 reg 4.736842e+04 train accuracy: 0.315286 val accuracy: 0.326000\n",
      "lr 1.210526e-07 reg 4.868421e+04 train accuracy: 0.307408 val accuracy: 0.328000\n",
      "lr 1.210526e-07 reg 5.000000e+04 train accuracy: 0.314633 val accuracy: 0.321000\n",
      "lr 1.421053e-07 reg 2.500000e+04 train accuracy: 0.334816 val accuracy: 0.343000\n",
      "lr 1.421053e-07 reg 2.631579e+04 train accuracy: 0.327510 val accuracy: 0.339000\n",
      "lr 1.421053e-07 reg 2.763158e+04 train accuracy: 0.326653 val accuracy: 0.344000\n",
      "lr 1.421053e-07 reg 2.894737e+04 train accuracy: 0.323551 val accuracy: 0.346000\n",
      "lr 1.421053e-07 reg 3.026316e+04 train accuracy: 0.326776 val accuracy: 0.338000\n",
      "lr 1.421053e-07 reg 3.157895e+04 train accuracy: 0.321694 val accuracy: 0.336000\n",
      "lr 1.421053e-07 reg 3.289474e+04 train accuracy: 0.324490 val accuracy: 0.337000\n",
      "lr 1.421053e-07 reg 3.421053e+04 train accuracy: 0.323796 val accuracy: 0.348000\n",
      "lr 1.421053e-07 reg 3.552632e+04 train accuracy: 0.318898 val accuracy: 0.335000\n",
      "lr 1.421053e-07 reg 3.684211e+04 train accuracy: 0.319429 val accuracy: 0.330000\n",
      "lr 1.421053e-07 reg 3.815789e+04 train accuracy: 0.318531 val accuracy: 0.325000\n",
      "lr 1.421053e-07 reg 3.947368e+04 train accuracy: 0.311122 val accuracy: 0.328000\n",
      "lr 1.421053e-07 reg 4.078947e+04 train accuracy: 0.316000 val accuracy: 0.335000\n",
      "lr 1.421053e-07 reg 4.210526e+04 train accuracy: 0.317020 val accuracy: 0.334000\n",
      "lr 1.421053e-07 reg 4.342105e+04 train accuracy: 0.316306 val accuracy: 0.327000\n",
      "lr 1.421053e-07 reg 4.473684e+04 train accuracy: 0.317000 val accuracy: 0.335000\n",
      "lr 1.421053e-07 reg 4.605263e+04 train accuracy: 0.315510 val accuracy: 0.326000\n",
      "lr 1.421053e-07 reg 4.736842e+04 train accuracy: 0.314408 val accuracy: 0.323000\n",
      "lr 1.421053e-07 reg 4.868421e+04 train accuracy: 0.303837 val accuracy: 0.320000\n",
      "lr 1.421053e-07 reg 5.000000e+04 train accuracy: 0.306367 val accuracy: 0.323000\n",
      "lr 1.631579e-07 reg 2.500000e+04 train accuracy: 0.331041 val accuracy: 0.344000\n",
      "lr 1.631579e-07 reg 2.631579e+04 train accuracy: 0.333102 val accuracy: 0.347000\n",
      "lr 1.631579e-07 reg 2.763158e+04 train accuracy: 0.329204 val accuracy: 0.341000\n",
      "lr 1.631579e-07 reg 2.894737e+04 train accuracy: 0.321041 val accuracy: 0.343000\n",
      "lr 1.631579e-07 reg 3.026316e+04 train accuracy: 0.326449 val accuracy: 0.334000\n",
      "lr 1.631579e-07 reg 3.157895e+04 train accuracy: 0.318408 val accuracy: 0.338000\n",
      "lr 1.631579e-07 reg 3.289474e+04 train accuracy: 0.317224 val accuracy: 0.334000\n",
      "lr 1.631579e-07 reg 3.421053e+04 train accuracy: 0.322714 val accuracy: 0.327000\n",
      "lr 1.631579e-07 reg 3.552632e+04 train accuracy: 0.316122 val accuracy: 0.332000\n",
      "lr 1.631579e-07 reg 3.684211e+04 train accuracy: 0.313694 val accuracy: 0.332000\n",
      "lr 1.631579e-07 reg 3.815789e+04 train accuracy: 0.319612 val accuracy: 0.331000\n",
      "lr 1.631579e-07 reg 3.947368e+04 train accuracy: 0.322959 val accuracy: 0.338000\n",
      "lr 1.631579e-07 reg 4.078947e+04 train accuracy: 0.311755 val accuracy: 0.325000\n",
      "lr 1.631579e-07 reg 4.210526e+04 train accuracy: 0.320816 val accuracy: 0.339000\n",
      "lr 1.631579e-07 reg 4.342105e+04 train accuracy: 0.314571 val accuracy: 0.337000\n",
      "lr 1.631579e-07 reg 4.473684e+04 train accuracy: 0.313224 val accuracy: 0.323000\n",
      "lr 1.631579e-07 reg 4.605263e+04 train accuracy: 0.314551 val accuracy: 0.320000\n",
      "lr 1.631579e-07 reg 4.736842e+04 train accuracy: 0.315061 val accuracy: 0.322000\n",
      "lr 1.631579e-07 reg 4.868421e+04 train accuracy: 0.297959 val accuracy: 0.315000\n",
      "lr 1.631579e-07 reg 5.000000e+04 train accuracy: 0.297429 val accuracy: 0.316000\n",
      "lr 1.842105e-07 reg 2.500000e+04 train accuracy: 0.324735 val accuracy: 0.347000\n",
      "lr 1.842105e-07 reg 2.631579e+04 train accuracy: 0.325653 val accuracy: 0.334000\n",
      "lr 1.842105e-07 reg 2.763158e+04 train accuracy: 0.332122 val accuracy: 0.344000\n",
      "lr 1.842105e-07 reg 2.894737e+04 train accuracy: 0.320959 val accuracy: 0.335000\n",
      "lr 1.842105e-07 reg 3.026316e+04 train accuracy: 0.326041 val accuracy: 0.347000\n",
      "lr 1.842105e-07 reg 3.157895e+04 train accuracy: 0.330449 val accuracy: 0.343000\n",
      "lr 1.842105e-07 reg 3.289474e+04 train accuracy: 0.318816 val accuracy: 0.338000\n",
      "lr 1.842105e-07 reg 3.421053e+04 train accuracy: 0.317490 val accuracy: 0.334000\n",
      "lr 1.842105e-07 reg 3.552632e+04 train accuracy: 0.316551 val accuracy: 0.328000\n",
      "lr 1.842105e-07 reg 3.684211e+04 train accuracy: 0.322020 val accuracy: 0.339000\n",
      "lr 1.842105e-07 reg 3.815789e+04 train accuracy: 0.317020 val accuracy: 0.338000\n",
      "lr 1.842105e-07 reg 3.947368e+04 train accuracy: 0.315306 val accuracy: 0.319000\n",
      "lr 1.842105e-07 reg 4.078947e+04 train accuracy: 0.321041 val accuracy: 0.333000\n",
      "lr 1.842105e-07 reg 4.210526e+04 train accuracy: 0.314878 val accuracy: 0.336000\n",
      "lr 1.842105e-07 reg 4.342105e+04 train accuracy: 0.311224 val accuracy: 0.326000\n",
      "lr 1.842105e-07 reg 4.473684e+04 train accuracy: 0.305061 val accuracy: 0.323000\n",
      "lr 1.842105e-07 reg 4.605263e+04 train accuracy: 0.306673 val accuracy: 0.315000\n",
      "lr 1.842105e-07 reg 4.736842e+04 train accuracy: 0.304531 val accuracy: 0.325000\n",
      "lr 1.842105e-07 reg 4.868421e+04 train accuracy: 0.309000 val accuracy: 0.329000\n",
      "lr 1.842105e-07 reg 5.000000e+04 train accuracy: 0.311980 val accuracy: 0.322000\n",
      "lr 2.052632e-07 reg 2.500000e+04 train accuracy: 0.325551 val accuracy: 0.333000\n",
      "lr 2.052632e-07 reg 2.631579e+04 train accuracy: 0.324857 val accuracy: 0.330000\n",
      "lr 2.052632e-07 reg 2.763158e+04 train accuracy: 0.318082 val accuracy: 0.339000\n",
      "lr 2.052632e-07 reg 2.894737e+04 train accuracy: 0.327980 val accuracy: 0.333000\n",
      "lr 2.052632e-07 reg 3.026316e+04 train accuracy: 0.323694 val accuracy: 0.335000\n",
      "lr 2.052632e-07 reg 3.157895e+04 train accuracy: 0.322551 val accuracy: 0.338000\n",
      "lr 2.052632e-07 reg 3.289474e+04 train accuracy: 0.312265 val accuracy: 0.329000\n",
      "lr 2.052632e-07 reg 3.421053e+04 train accuracy: 0.319163 val accuracy: 0.330000\n",
      "lr 2.052632e-07 reg 3.552632e+04 train accuracy: 0.316918 val accuracy: 0.327000\n",
      "lr 2.052632e-07 reg 3.684211e+04 train accuracy: 0.314612 val accuracy: 0.331000\n",
      "lr 2.052632e-07 reg 3.815789e+04 train accuracy: 0.313490 val accuracy: 0.335000\n",
      "lr 2.052632e-07 reg 3.947368e+04 train accuracy: 0.309143 val accuracy: 0.325000\n",
      "lr 2.052632e-07 reg 4.078947e+04 train accuracy: 0.315408 val accuracy: 0.331000\n",
      "lr 2.052632e-07 reg 4.210526e+04 train accuracy: 0.320408 val accuracy: 0.329000\n",
      "lr 2.052632e-07 reg 4.342105e+04 train accuracy: 0.317796 val accuracy: 0.327000\n",
      "lr 2.052632e-07 reg 4.473684e+04 train accuracy: 0.317367 val accuracy: 0.336000\n",
      "lr 2.052632e-07 reg 4.605263e+04 train accuracy: 0.312735 val accuracy: 0.341000\n",
      "lr 2.052632e-07 reg 4.736842e+04 train accuracy: 0.304918 val accuracy: 0.329000\n",
      "lr 2.052632e-07 reg 4.868421e+04 train accuracy: 0.311388 val accuracy: 0.326000\n",
      "lr 2.052632e-07 reg 5.000000e+04 train accuracy: 0.300102 val accuracy: 0.318000\n",
      "lr 2.263158e-07 reg 2.500000e+04 train accuracy: 0.329796 val accuracy: 0.340000\n",
      "lr 2.263158e-07 reg 2.631579e+04 train accuracy: 0.327000 val accuracy: 0.348000\n",
      "lr 2.263158e-07 reg 2.763158e+04 train accuracy: 0.322143 val accuracy: 0.339000\n",
      "lr 2.263158e-07 reg 2.894737e+04 train accuracy: 0.323327 val accuracy: 0.330000\n",
      "lr 2.263158e-07 reg 3.026316e+04 train accuracy: 0.309571 val accuracy: 0.327000\n",
      "lr 2.263158e-07 reg 3.157895e+04 train accuracy: 0.318816 val accuracy: 0.338000\n",
      "lr 2.263158e-07 reg 3.289474e+04 train accuracy: 0.320327 val accuracy: 0.338000\n",
      "lr 2.263158e-07 reg 3.421053e+04 train accuracy: 0.320449 val accuracy: 0.336000\n",
      "lr 2.263158e-07 reg 3.552632e+04 train accuracy: 0.317388 val accuracy: 0.329000\n",
      "lr 2.263158e-07 reg 3.684211e+04 train accuracy: 0.314224 val accuracy: 0.326000\n",
      "lr 2.263158e-07 reg 3.815789e+04 train accuracy: 0.314735 val accuracy: 0.330000\n",
      "lr 2.263158e-07 reg 3.947368e+04 train accuracy: 0.310327 val accuracy: 0.324000\n",
      "lr 2.263158e-07 reg 4.078947e+04 train accuracy: 0.311980 val accuracy: 0.324000\n",
      "lr 2.263158e-07 reg 4.210526e+04 train accuracy: 0.302714 val accuracy: 0.311000\n",
      "lr 2.263158e-07 reg 4.342105e+04 train accuracy: 0.303735 val accuracy: 0.314000\n",
      "lr 2.263158e-07 reg 4.473684e+04 train accuracy: 0.311510 val accuracy: 0.328000\n",
      "lr 2.263158e-07 reg 4.605263e+04 train accuracy: 0.301714 val accuracy: 0.313000\n",
      "lr 2.263158e-07 reg 4.736842e+04 train accuracy: 0.312102 val accuracy: 0.320000\n",
      "lr 2.263158e-07 reg 4.868421e+04 train accuracy: 0.307163 val accuracy: 0.311000\n",
      "lr 2.263158e-07 reg 5.000000e+04 train accuracy: 0.311082 val accuracy: 0.322000\n",
      "lr 2.473684e-07 reg 2.500000e+04 train accuracy: 0.331000 val accuracy: 0.338000\n",
      "lr 2.473684e-07 reg 2.631579e+04 train accuracy: 0.333245 val accuracy: 0.349000\n",
      "lr 2.473684e-07 reg 2.763158e+04 train accuracy: 0.324898 val accuracy: 0.340000\n",
      "lr 2.473684e-07 reg 2.894737e+04 train accuracy: 0.322980 val accuracy: 0.339000\n",
      "lr 2.473684e-07 reg 3.026316e+04 train accuracy: 0.325082 val accuracy: 0.345000\n",
      "lr 2.473684e-07 reg 3.157895e+04 train accuracy: 0.322653 val accuracy: 0.332000\n",
      "lr 2.473684e-07 reg 3.289474e+04 train accuracy: 0.315939 val accuracy: 0.327000\n",
      "lr 2.473684e-07 reg 3.421053e+04 train accuracy: 0.305878 val accuracy: 0.329000\n",
      "lr 2.473684e-07 reg 3.552632e+04 train accuracy: 0.316041 val accuracy: 0.337000\n",
      "lr 2.473684e-07 reg 3.684211e+04 train accuracy: 0.304510 val accuracy: 0.328000\n",
      "lr 2.473684e-07 reg 3.815789e+04 train accuracy: 0.310878 val accuracy: 0.325000\n",
      "lr 2.473684e-07 reg 3.947368e+04 train accuracy: 0.314510 val accuracy: 0.328000\n",
      "lr 2.473684e-07 reg 4.078947e+04 train accuracy: 0.314429 val accuracy: 0.332000\n",
      "lr 2.473684e-07 reg 4.210526e+04 train accuracy: 0.312020 val accuracy: 0.332000\n",
      "lr 2.473684e-07 reg 4.342105e+04 train accuracy: 0.310143 val accuracy: 0.323000\n",
      "lr 2.473684e-07 reg 4.473684e+04 train accuracy: 0.301837 val accuracy: 0.323000\n",
      "lr 2.473684e-07 reg 4.605263e+04 train accuracy: 0.294408 val accuracy: 0.315000\n",
      "lr 2.473684e-07 reg 4.736842e+04 train accuracy: 0.300041 val accuracy: 0.317000\n",
      "lr 2.473684e-07 reg 4.868421e+04 train accuracy: 0.307388 val accuracy: 0.320000\n",
      "lr 2.473684e-07 reg 5.000000e+04 train accuracy: 0.313061 val accuracy: 0.330000\n",
      "lr 2.684211e-07 reg 2.500000e+04 train accuracy: 0.335429 val accuracy: 0.350000\n",
      "lr 2.684211e-07 reg 2.631579e+04 train accuracy: 0.327163 val accuracy: 0.338000\n",
      "lr 2.684211e-07 reg 2.763158e+04 train accuracy: 0.328347 val accuracy: 0.344000\n",
      "lr 2.684211e-07 reg 2.894737e+04 train accuracy: 0.322122 val accuracy: 0.332000\n",
      "lr 2.684211e-07 reg 3.026316e+04 train accuracy: 0.324857 val accuracy: 0.336000\n",
      "lr 2.684211e-07 reg 3.157895e+04 train accuracy: 0.315000 val accuracy: 0.332000\n",
      "lr 2.684211e-07 reg 3.289474e+04 train accuracy: 0.323592 val accuracy: 0.330000\n",
      "lr 2.684211e-07 reg 3.421053e+04 train accuracy: 0.314551 val accuracy: 0.339000\n",
      "lr 2.684211e-07 reg 3.552632e+04 train accuracy: 0.325224 val accuracy: 0.340000\n",
      "lr 2.684211e-07 reg 3.684211e+04 train accuracy: 0.312551 val accuracy: 0.326000\n",
      "lr 2.684211e-07 reg 3.815789e+04 train accuracy: 0.308469 val accuracy: 0.325000\n",
      "lr 2.684211e-07 reg 3.947368e+04 train accuracy: 0.316429 val accuracy: 0.333000\n",
      "lr 2.684211e-07 reg 4.078947e+04 train accuracy: 0.302327 val accuracy: 0.316000\n",
      "lr 2.684211e-07 reg 4.210526e+04 train accuracy: 0.303837 val accuracy: 0.326000\n",
      "lr 2.684211e-07 reg 4.342105e+04 train accuracy: 0.312082 val accuracy: 0.327000\n",
      "lr 2.684211e-07 reg 4.473684e+04 train accuracy: 0.313551 val accuracy: 0.321000\n",
      "lr 2.684211e-07 reg 4.605263e+04 train accuracy: 0.300102 val accuracy: 0.312000\n",
      "lr 2.684211e-07 reg 4.736842e+04 train accuracy: 0.311980 val accuracy: 0.326000\n",
      "lr 2.684211e-07 reg 4.868421e+04 train accuracy: 0.314796 val accuracy: 0.334000\n",
      "lr 2.684211e-07 reg 5.000000e+04 train accuracy: 0.293490 val accuracy: 0.306000\n",
      "lr 2.894737e-07 reg 2.500000e+04 train accuracy: 0.331653 val accuracy: 0.352000\n",
      "lr 2.894737e-07 reg 2.631579e+04 train accuracy: 0.324265 val accuracy: 0.338000\n",
      "lr 2.894737e-07 reg 2.763158e+04 train accuracy: 0.326367 val accuracy: 0.340000\n",
      "lr 2.894737e-07 reg 2.894737e+04 train accuracy: 0.315224 val accuracy: 0.333000\n",
      "lr 2.894737e-07 reg 3.026316e+04 train accuracy: 0.312143 val accuracy: 0.326000\n",
      "lr 2.894737e-07 reg 3.157895e+04 train accuracy: 0.324694 val accuracy: 0.333000\n",
      "lr 2.894737e-07 reg 3.289474e+04 train accuracy: 0.316796 val accuracy: 0.328000\n",
      "lr 2.894737e-07 reg 3.421053e+04 train accuracy: 0.321898 val accuracy: 0.339000\n",
      "lr 2.894737e-07 reg 3.552632e+04 train accuracy: 0.321082 val accuracy: 0.330000\n",
      "lr 2.894737e-07 reg 3.684211e+04 train accuracy: 0.312531 val accuracy: 0.333000\n",
      "lr 2.894737e-07 reg 3.815789e+04 train accuracy: 0.308857 val accuracy: 0.320000\n",
      "lr 2.894737e-07 reg 3.947368e+04 train accuracy: 0.322857 val accuracy: 0.343000\n",
      "lr 2.894737e-07 reg 4.078947e+04 train accuracy: 0.312245 val accuracy: 0.323000\n",
      "lr 2.894737e-07 reg 4.210526e+04 train accuracy: 0.308531 val accuracy: 0.317000\n",
      "lr 2.894737e-07 reg 4.342105e+04 train accuracy: 0.320816 val accuracy: 0.329000\n",
      "lr 2.894737e-07 reg 4.473684e+04 train accuracy: 0.309776 val accuracy: 0.323000\n",
      "lr 2.894737e-07 reg 4.605263e+04 train accuracy: 0.300776 val accuracy: 0.314000\n",
      "lr 2.894737e-07 reg 4.736842e+04 train accuracy: 0.313959 val accuracy: 0.332000\n",
      "lr 2.894737e-07 reg 4.868421e+04 train accuracy: 0.299327 val accuracy: 0.319000\n",
      "lr 2.894737e-07 reg 5.000000e+04 train accuracy: 0.306286 val accuracy: 0.312000\n",
      "lr 3.105263e-07 reg 2.500000e+04 train accuracy: 0.327980 val accuracy: 0.336000\n",
      "lr 3.105263e-07 reg 2.631579e+04 train accuracy: 0.323224 val accuracy: 0.338000\n",
      "lr 3.105263e-07 reg 2.763158e+04 train accuracy: 0.317571 val accuracy: 0.332000\n",
      "lr 3.105263e-07 reg 2.894737e+04 train accuracy: 0.324163 val accuracy: 0.338000\n",
      "lr 3.105263e-07 reg 3.026316e+04 train accuracy: 0.314571 val accuracy: 0.333000\n",
      "lr 3.105263e-07 reg 3.157895e+04 train accuracy: 0.313755 val accuracy: 0.325000\n",
      "lr 3.105263e-07 reg 3.289474e+04 train accuracy: 0.311673 val accuracy: 0.331000\n",
      "lr 3.105263e-07 reg 3.421053e+04 train accuracy: 0.316735 val accuracy: 0.324000\n",
      "lr 3.105263e-07 reg 3.552632e+04 train accuracy: 0.315082 val accuracy: 0.328000\n",
      "lr 3.105263e-07 reg 3.684211e+04 train accuracy: 0.310306 val accuracy: 0.330000\n",
      "lr 3.105263e-07 reg 3.815789e+04 train accuracy: 0.323918 val accuracy: 0.341000\n",
      "lr 3.105263e-07 reg 3.947368e+04 train accuracy: 0.313959 val accuracy: 0.331000\n",
      "lr 3.105263e-07 reg 4.078947e+04 train accuracy: 0.311878 val accuracy: 0.327000\n",
      "lr 3.105263e-07 reg 4.210526e+04 train accuracy: 0.314469 val accuracy: 0.324000\n",
      "lr 3.105263e-07 reg 4.342105e+04 train accuracy: 0.306837 val accuracy: 0.316000\n",
      "lr 3.105263e-07 reg 4.473684e+04 train accuracy: 0.310265 val accuracy: 0.320000\n",
      "lr 3.105263e-07 reg 4.605263e+04 train accuracy: 0.316163 val accuracy: 0.326000\n",
      "lr 3.105263e-07 reg 4.736842e+04 train accuracy: 0.300449 val accuracy: 0.323000\n",
      "lr 3.105263e-07 reg 4.868421e+04 train accuracy: 0.300367 val accuracy: 0.312000\n",
      "lr 3.105263e-07 reg 5.000000e+04 train accuracy: 0.303857 val accuracy: 0.320000\n",
      "lr 3.315789e-07 reg 2.500000e+04 train accuracy: 0.324918 val accuracy: 0.348000\n",
      "lr 3.315789e-07 reg 2.631579e+04 train accuracy: 0.316796 val accuracy: 0.330000\n",
      "lr 3.315789e-07 reg 2.763158e+04 train accuracy: 0.318224 val accuracy: 0.331000\n",
      "lr 3.315789e-07 reg 2.894737e+04 train accuracy: 0.325918 val accuracy: 0.333000\n",
      "lr 3.315789e-07 reg 3.026316e+04 train accuracy: 0.327102 val accuracy: 0.343000\n",
      "lr 3.315789e-07 reg 3.157895e+04 train accuracy: 0.316000 val accuracy: 0.340000\n",
      "lr 3.315789e-07 reg 3.289474e+04 train accuracy: 0.310837 val accuracy: 0.322000\n",
      "lr 3.315789e-07 reg 3.421053e+04 train accuracy: 0.311163 val accuracy: 0.328000\n",
      "lr 3.315789e-07 reg 3.552632e+04 train accuracy: 0.321612 val accuracy: 0.339000\n",
      "lr 3.315789e-07 reg 3.684211e+04 train accuracy: 0.313204 val accuracy: 0.331000\n",
      "lr 3.315789e-07 reg 3.815789e+04 train accuracy: 0.317959 val accuracy: 0.329000\n",
      "lr 3.315789e-07 reg 3.947368e+04 train accuracy: 0.308102 val accuracy: 0.328000\n",
      "lr 3.315789e-07 reg 4.078947e+04 train accuracy: 0.310837 val accuracy: 0.321000\n",
      "lr 3.315789e-07 reg 4.210526e+04 train accuracy: 0.314245 val accuracy: 0.333000\n",
      "lr 3.315789e-07 reg 4.342105e+04 train accuracy: 0.307653 val accuracy: 0.333000\n",
      "lr 3.315789e-07 reg 4.473684e+04 train accuracy: 0.309714 val accuracy: 0.318000\n",
      "lr 3.315789e-07 reg 4.605263e+04 train accuracy: 0.293449 val accuracy: 0.306000\n",
      "lr 3.315789e-07 reg 4.736842e+04 train accuracy: 0.313612 val accuracy: 0.328000\n",
      "lr 3.315789e-07 reg 4.868421e+04 train accuracy: 0.311020 val accuracy: 0.325000\n",
      "lr 3.315789e-07 reg 5.000000e+04 train accuracy: 0.305122 val accuracy: 0.320000\n",
      "lr 3.526316e-07 reg 2.500000e+04 train accuracy: 0.322776 val accuracy: 0.339000\n",
      "lr 3.526316e-07 reg 2.631579e+04 train accuracy: 0.324959 val accuracy: 0.338000\n",
      "lr 3.526316e-07 reg 2.763158e+04 train accuracy: 0.325245 val accuracy: 0.348000\n",
      "lr 3.526316e-07 reg 2.894737e+04 train accuracy: 0.321429 val accuracy: 0.341000\n",
      "lr 3.526316e-07 reg 3.026316e+04 train accuracy: 0.322959 val accuracy: 0.338000\n",
      "lr 3.526316e-07 reg 3.157895e+04 train accuracy: 0.315898 val accuracy: 0.322000\n",
      "lr 3.526316e-07 reg 3.289474e+04 train accuracy: 0.315204 val accuracy: 0.325000\n",
      "lr 3.526316e-07 reg 3.421053e+04 train accuracy: 0.321735 val accuracy: 0.335000\n",
      "lr 3.526316e-07 reg 3.552632e+04 train accuracy: 0.310776 val accuracy: 0.333000\n",
      "lr 3.526316e-07 reg 3.684211e+04 train accuracy: 0.314857 val accuracy: 0.321000\n",
      "lr 3.526316e-07 reg 3.815789e+04 train accuracy: 0.315939 val accuracy: 0.338000\n",
      "lr 3.526316e-07 reg 3.947368e+04 train accuracy: 0.310490 val accuracy: 0.323000\n",
      "lr 3.526316e-07 reg 4.078947e+04 train accuracy: 0.304592 val accuracy: 0.320000\n",
      "lr 3.526316e-07 reg 4.210526e+04 train accuracy: 0.300980 val accuracy: 0.317000\n",
      "lr 3.526316e-07 reg 4.342105e+04 train accuracy: 0.318776 val accuracy: 0.328000\n",
      "lr 3.526316e-07 reg 4.473684e+04 train accuracy: 0.298776 val accuracy: 0.319000\n",
      "lr 3.526316e-07 reg 4.605263e+04 train accuracy: 0.296694 val accuracy: 0.323000\n",
      "lr 3.526316e-07 reg 4.736842e+04 train accuracy: 0.305980 val accuracy: 0.330000\n",
      "lr 3.526316e-07 reg 4.868421e+04 train accuracy: 0.297510 val accuracy: 0.317000\n",
      "lr 3.526316e-07 reg 5.000000e+04 train accuracy: 0.312327 val accuracy: 0.326000\n",
      "lr 3.736842e-07 reg 2.500000e+04 train accuracy: 0.320551 val accuracy: 0.339000\n",
      "lr 3.736842e-07 reg 2.631579e+04 train accuracy: 0.328204 val accuracy: 0.346000\n",
      "lr 3.736842e-07 reg 2.763158e+04 train accuracy: 0.319612 val accuracy: 0.334000\n",
      "lr 3.736842e-07 reg 2.894737e+04 train accuracy: 0.310327 val accuracy: 0.328000\n",
      "lr 3.736842e-07 reg 3.026316e+04 train accuracy: 0.322224 val accuracy: 0.330000\n",
      "lr 3.736842e-07 reg 3.157895e+04 train accuracy: 0.314816 val accuracy: 0.324000\n",
      "lr 3.736842e-07 reg 3.289474e+04 train accuracy: 0.310571 val accuracy: 0.321000\n",
      "lr 3.736842e-07 reg 3.421053e+04 train accuracy: 0.315531 val accuracy: 0.331000\n",
      "lr 3.736842e-07 reg 3.552632e+04 train accuracy: 0.326204 val accuracy: 0.336000\n",
      "lr 3.736842e-07 reg 3.684211e+04 train accuracy: 0.318653 val accuracy: 0.322000\n",
      "lr 3.736842e-07 reg 3.815789e+04 train accuracy: 0.304796 val accuracy: 0.310000\n",
      "lr 3.736842e-07 reg 3.947368e+04 train accuracy: 0.313673 val accuracy: 0.329000\n",
      "lr 3.736842e-07 reg 4.078947e+04 train accuracy: 0.305020 val accuracy: 0.326000\n",
      "lr 3.736842e-07 reg 4.210526e+04 train accuracy: 0.308122 val accuracy: 0.310000\n",
      "lr 3.736842e-07 reg 4.342105e+04 train accuracy: 0.318551 val accuracy: 0.328000\n",
      "lr 3.736842e-07 reg 4.473684e+04 train accuracy: 0.305347 val accuracy: 0.328000\n",
      "lr 3.736842e-07 reg 4.605263e+04 train accuracy: 0.303633 val accuracy: 0.333000\n",
      "lr 3.736842e-07 reg 4.736842e+04 train accuracy: 0.306041 val accuracy: 0.311000\n",
      "lr 3.736842e-07 reg 4.868421e+04 train accuracy: 0.305551 val accuracy: 0.310000\n",
      "lr 3.736842e-07 reg 5.000000e+04 train accuracy: 0.297347 val accuracy: 0.310000\n",
      "lr 3.947368e-07 reg 2.500000e+04 train accuracy: 0.320490 val accuracy: 0.348000\n",
      "lr 3.947368e-07 reg 2.631579e+04 train accuracy: 0.325857 val accuracy: 0.345000\n",
      "lr 3.947368e-07 reg 2.763158e+04 train accuracy: 0.326286 val accuracy: 0.342000\n",
      "lr 3.947368e-07 reg 2.894737e+04 train accuracy: 0.323735 val accuracy: 0.338000\n",
      "lr 3.947368e-07 reg 3.026316e+04 train accuracy: 0.318755 val accuracy: 0.333000\n",
      "lr 3.947368e-07 reg 3.157895e+04 train accuracy: 0.314571 val accuracy: 0.333000\n",
      "lr 3.947368e-07 reg 3.289474e+04 train accuracy: 0.320429 val accuracy: 0.337000\n",
      "lr 3.947368e-07 reg 3.421053e+04 train accuracy: 0.326143 val accuracy: 0.343000\n",
      "lr 3.947368e-07 reg 3.552632e+04 train accuracy: 0.316776 val accuracy: 0.326000\n",
      "lr 3.947368e-07 reg 3.684211e+04 train accuracy: 0.313694 val accuracy: 0.312000\n",
      "lr 3.947368e-07 reg 3.815789e+04 train accuracy: 0.304551 val accuracy: 0.303000\n",
      "lr 3.947368e-07 reg 3.947368e+04 train accuracy: 0.319000 val accuracy: 0.329000\n",
      "lr 3.947368e-07 reg 4.078947e+04 train accuracy: 0.316429 val accuracy: 0.323000\n",
      "lr 3.947368e-07 reg 4.210526e+04 train accuracy: 0.312571 val accuracy: 0.326000\n",
      "lr 3.947368e-07 reg 4.342105e+04 train accuracy: 0.306714 val accuracy: 0.319000\n",
      "lr 3.947368e-07 reg 4.473684e+04 train accuracy: 0.304204 val accuracy: 0.318000\n",
      "lr 3.947368e-07 reg 4.605263e+04 train accuracy: 0.282184 val accuracy: 0.292000\n",
      "lr 3.947368e-07 reg 4.736842e+04 train accuracy: 0.303449 val accuracy: 0.325000\n",
      "lr 3.947368e-07 reg 4.868421e+04 train accuracy: 0.305551 val accuracy: 0.311000\n",
      "lr 3.947368e-07 reg 5.000000e+04 train accuracy: 0.293245 val accuracy: 0.313000\n",
      "lr 4.157895e-07 reg 2.500000e+04 train accuracy: 0.318122 val accuracy: 0.341000\n",
      "lr 4.157895e-07 reg 2.631579e+04 train accuracy: 0.319653 val accuracy: 0.320000\n",
      "lr 4.157895e-07 reg 2.763158e+04 train accuracy: 0.333531 val accuracy: 0.346000\n",
      "lr 4.157895e-07 reg 2.894737e+04 train accuracy: 0.328469 val accuracy: 0.347000\n",
      "lr 4.157895e-07 reg 3.026316e+04 train accuracy: 0.318490 val accuracy: 0.341000\n",
      "lr 4.157895e-07 reg 3.157895e+04 train accuracy: 0.318408 val accuracy: 0.331000\n",
      "lr 4.157895e-07 reg 3.289474e+04 train accuracy: 0.324306 val accuracy: 0.327000\n",
      "lr 4.157895e-07 reg 3.421053e+04 train accuracy: 0.310408 val accuracy: 0.328000\n",
      "lr 4.157895e-07 reg 3.552632e+04 train accuracy: 0.313367 val accuracy: 0.325000\n",
      "lr 4.157895e-07 reg 3.684211e+04 train accuracy: 0.309388 val accuracy: 0.330000\n",
      "lr 4.157895e-07 reg 3.815789e+04 train accuracy: 0.317204 val accuracy: 0.327000\n",
      "lr 4.157895e-07 reg 3.947368e+04 train accuracy: 0.303490 val accuracy: 0.319000\n",
      "lr 4.157895e-07 reg 4.078947e+04 train accuracy: 0.300878 val accuracy: 0.317000\n",
      "lr 4.157895e-07 reg 4.210526e+04 train accuracy: 0.304122 val accuracy: 0.317000\n",
      "lr 4.157895e-07 reg 4.342105e+04 train accuracy: 0.292551 val accuracy: 0.311000\n",
      "lr 4.157895e-07 reg 4.473684e+04 train accuracy: 0.307959 val accuracy: 0.329000\n",
      "lr 4.157895e-07 reg 4.605263e+04 train accuracy: 0.312204 val accuracy: 0.324000\n",
      "lr 4.157895e-07 reg 4.736842e+04 train accuracy: 0.312041 val accuracy: 0.320000\n",
      "lr 4.157895e-07 reg 4.868421e+04 train accuracy: 0.309510 val accuracy: 0.325000\n",
      "lr 4.157895e-07 reg 5.000000e+04 train accuracy: 0.297286 val accuracy: 0.323000\n",
      "lr 4.368421e-07 reg 2.500000e+04 train accuracy: 0.324388 val accuracy: 0.337000\n",
      "lr 4.368421e-07 reg 2.631579e+04 train accuracy: 0.323898 val accuracy: 0.336000\n",
      "lr 4.368421e-07 reg 2.763158e+04 train accuracy: 0.308755 val accuracy: 0.324000\n",
      "lr 4.368421e-07 reg 2.894737e+04 train accuracy: 0.322673 val accuracy: 0.338000\n",
      "lr 4.368421e-07 reg 3.026316e+04 train accuracy: 0.324816 val accuracy: 0.336000\n",
      "lr 4.368421e-07 reg 3.157895e+04 train accuracy: 0.306347 val accuracy: 0.321000\n",
      "lr 4.368421e-07 reg 3.289474e+04 train accuracy: 0.323000 val accuracy: 0.339000\n",
      "lr 4.368421e-07 reg 3.421053e+04 train accuracy: 0.309714 val accuracy: 0.331000\n",
      "lr 4.368421e-07 reg 3.552632e+04 train accuracy: 0.309735 val accuracy: 0.322000\n",
      "lr 4.368421e-07 reg 3.684211e+04 train accuracy: 0.304061 val accuracy: 0.323000\n",
      "lr 4.368421e-07 reg 3.815789e+04 train accuracy: 0.305857 val accuracy: 0.319000\n",
      "lr 4.368421e-07 reg 3.947368e+04 train accuracy: 0.320735 val accuracy: 0.342000\n",
      "lr 4.368421e-07 reg 4.078947e+04 train accuracy: 0.317163 val accuracy: 0.337000\n",
      "lr 4.368421e-07 reg 4.210526e+04 train accuracy: 0.310327 val accuracy: 0.322000\n",
      "lr 4.368421e-07 reg 4.342105e+04 train accuracy: 0.313857 val accuracy: 0.322000\n",
      "lr 4.368421e-07 reg 4.473684e+04 train accuracy: 0.318776 val accuracy: 0.335000\n",
      "lr 4.368421e-07 reg 4.605263e+04 train accuracy: 0.318367 val accuracy: 0.328000\n",
      "lr 4.368421e-07 reg 4.736842e+04 train accuracy: 0.303306 val accuracy: 0.315000\n",
      "lr 4.368421e-07 reg 4.868421e+04 train accuracy: 0.305735 val accuracy: 0.318000\n",
      "lr 4.368421e-07 reg 5.000000e+04 train accuracy: 0.297694 val accuracy: 0.316000\n",
      "lr 4.578947e-07 reg 2.500000e+04 train accuracy: 0.333082 val accuracy: 0.345000\n",
      "lr 4.578947e-07 reg 2.631579e+04 train accuracy: 0.325776 val accuracy: 0.342000\n",
      "lr 4.578947e-07 reg 2.763158e+04 train accuracy: 0.331653 val accuracy: 0.343000\n",
      "lr 4.578947e-07 reg 2.894737e+04 train accuracy: 0.317592 val accuracy: 0.333000\n",
      "lr 4.578947e-07 reg 3.026316e+04 train accuracy: 0.315306 val accuracy: 0.318000\n",
      "lr 4.578947e-07 reg 3.157895e+04 train accuracy: 0.303857 val accuracy: 0.314000\n",
      "lr 4.578947e-07 reg 3.289474e+04 train accuracy: 0.314939 val accuracy: 0.335000\n",
      "lr 4.578947e-07 reg 3.421053e+04 train accuracy: 0.314082 val accuracy: 0.330000\n",
      "lr 4.578947e-07 reg 3.552632e+04 train accuracy: 0.311918 val accuracy: 0.323000\n",
      "lr 4.578947e-07 reg 3.684211e+04 train accuracy: 0.323265 val accuracy: 0.344000\n",
      "lr 4.578947e-07 reg 3.815789e+04 train accuracy: 0.314857 val accuracy: 0.329000\n",
      "lr 4.578947e-07 reg 3.947368e+04 train accuracy: 0.313571 val accuracy: 0.330000\n",
      "lr 4.578947e-07 reg 4.078947e+04 train accuracy: 0.318735 val accuracy: 0.332000\n",
      "lr 4.578947e-07 reg 4.210526e+04 train accuracy: 0.304102 val accuracy: 0.328000\n",
      "lr 4.578947e-07 reg 4.342105e+04 train accuracy: 0.303592 val accuracy: 0.324000\n",
      "lr 4.578947e-07 reg 4.473684e+04 train accuracy: 0.304306 val accuracy: 0.322000\n",
      "lr 4.578947e-07 reg 4.605263e+04 train accuracy: 0.299224 val accuracy: 0.313000\n",
      "lr 4.578947e-07 reg 4.736842e+04 train accuracy: 0.299735 val accuracy: 0.315000\n",
      "lr 4.578947e-07 reg 4.868421e+04 train accuracy: 0.318327 val accuracy: 0.332000\n",
      "lr 4.578947e-07 reg 5.000000e+04 train accuracy: 0.301531 val accuracy: 0.316000\n",
      "lr 4.789474e-07 reg 2.500000e+04 train accuracy: 0.334408 val accuracy: 0.356000\n",
      "lr 4.789474e-07 reg 2.631579e+04 train accuracy: 0.332102 val accuracy: 0.349000\n",
      "lr 4.789474e-07 reg 2.763158e+04 train accuracy: 0.323347 val accuracy: 0.338000\n",
      "lr 4.789474e-07 reg 2.894737e+04 train accuracy: 0.314837 val accuracy: 0.327000\n",
      "lr 4.789474e-07 reg 3.026316e+04 train accuracy: 0.323857 val accuracy: 0.343000\n",
      "lr 4.789474e-07 reg 3.157895e+04 train accuracy: 0.309551 val accuracy: 0.325000\n",
      "lr 4.789474e-07 reg 3.289474e+04 train accuracy: 0.325408 val accuracy: 0.336000\n",
      "lr 4.789474e-07 reg 3.421053e+04 train accuracy: 0.318306 val accuracy: 0.331000\n",
      "lr 4.789474e-07 reg 3.552632e+04 train accuracy: 0.302061 val accuracy: 0.318000\n",
      "lr 4.789474e-07 reg 3.684211e+04 train accuracy: 0.315163 val accuracy: 0.320000\n",
      "lr 4.789474e-07 reg 3.815789e+04 train accuracy: 0.309592 val accuracy: 0.311000\n",
      "lr 4.789474e-07 reg 3.947368e+04 train accuracy: 0.301898 val accuracy: 0.324000\n",
      "lr 4.789474e-07 reg 4.078947e+04 train accuracy: 0.313735 val accuracy: 0.325000\n",
      "lr 4.789474e-07 reg 4.210526e+04 train accuracy: 0.307224 val accuracy: 0.334000\n",
      "lr 4.789474e-07 reg 4.342105e+04 train accuracy: 0.309224 val accuracy: 0.327000\n",
      "lr 4.789474e-07 reg 4.473684e+04 train accuracy: 0.297755 val accuracy: 0.313000\n",
      "lr 4.789474e-07 reg 4.605263e+04 train accuracy: 0.306673 val accuracy: 0.327000\n",
      "lr 4.789474e-07 reg 4.736842e+04 train accuracy: 0.306918 val accuracy: 0.322000\n",
      "lr 4.789474e-07 reg 4.868421e+04 train accuracy: 0.303551 val accuracy: 0.320000\n",
      "lr 4.789474e-07 reg 5.000000e+04 train accuracy: 0.309000 val accuracy: 0.325000\n",
      "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.335796 val accuracy: 0.332000\n",
      "lr 5.000000e-07 reg 2.631579e+04 train accuracy: 0.323020 val accuracy: 0.345000\n",
      "lr 5.000000e-07 reg 2.763158e+04 train accuracy: 0.312735 val accuracy: 0.334000\n",
      "lr 5.000000e-07 reg 2.894737e+04 train accuracy: 0.321633 val accuracy: 0.337000\n",
      "lr 5.000000e-07 reg 3.026316e+04 train accuracy: 0.319061 val accuracy: 0.343000\n",
      "lr 5.000000e-07 reg 3.157895e+04 train accuracy: 0.323469 val accuracy: 0.326000\n",
      "lr 5.000000e-07 reg 3.289474e+04 train accuracy: 0.325327 val accuracy: 0.331000\n",
      "lr 5.000000e-07 reg 3.421053e+04 train accuracy: 0.303327 val accuracy: 0.319000\n",
      "lr 5.000000e-07 reg 3.552632e+04 train accuracy: 0.313122 val accuracy: 0.330000\n",
      "lr 5.000000e-07 reg 3.684211e+04 train accuracy: 0.307571 val accuracy: 0.330000\n",
      "lr 5.000000e-07 reg 3.815789e+04 train accuracy: 0.323327 val accuracy: 0.329000\n",
      "lr 5.000000e-07 reg 3.947368e+04 train accuracy: 0.298714 val accuracy: 0.314000\n",
      "lr 5.000000e-07 reg 4.078947e+04 train accuracy: 0.300816 val accuracy: 0.315000\n",
      "lr 5.000000e-07 reg 4.210526e+04 train accuracy: 0.310306 val accuracy: 0.338000\n",
      "lr 5.000000e-07 reg 4.342105e+04 train accuracy: 0.297714 val accuracy: 0.301000\n",
      "lr 5.000000e-07 reg 4.473684e+04 train accuracy: 0.291531 val accuracy: 0.307000\n",
      "lr 5.000000e-07 reg 4.605263e+04 train accuracy: 0.308673 val accuracy: 0.325000\n",
      "lr 5.000000e-07 reg 4.736842e+04 train accuracy: 0.298306 val accuracy: 0.313000\n",
      "lr 5.000000e-07 reg 4.868421e+04 train accuracy: 0.292143 val accuracy: 0.309000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.302163 val accuracy: 0.320000\n",
      "best validation accuracy achieved during cross-validation: 0.356000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "pass\n",
    "for lr in np.linspace(learning_rates[0], learning_rates[1], num=20):\n",
    "    for reg in np.linspace(regularization_strengths[0], regularization_strengths[1], 20):\n",
    "        softmax = Softmax()\n",
    "        softmax.train(X_train, y_train, learning_rate=lr, reg=reg,\n",
    "                      num_iters=1500, verbose=False)\n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        train_accuracy=np.mean(y_train == y_train_pred)\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        valid_accuracy=np.mean(y_val == y_val_pred)\n",
    "        results[(lr, reg)]=(train_accuracy,valid_accuracy)\n",
    "        if valid_accuracy>best_val:\n",
    "            best_val=valid_accuracy\n",
    "            best_softmax=softmax\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.347000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAF8CAYAAADrUz6WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nELgD8TEVCAQCgUAgcAf+B8I8txzF2bdqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c9e34a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
